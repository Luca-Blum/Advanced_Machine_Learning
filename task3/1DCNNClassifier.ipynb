{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+y5B4f0zct0zjm3PQ0Vfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lblum95/AML/blob/master/task3/1DCNNClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WLT-Y2M09Lh"
      },
      "source": [
        "# 1DCNNClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wB2ywzs1D0c"
      },
      "source": [
        "## Connect to My Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu-mBOOmt8IY",
        "outputId": "cdbcbe31-da87-4646-f8ba-01adce9541b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rEClcDK1IOZ"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YIvjO3No6SL"
      },
      "source": [
        "#general\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#sklearn\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
        "#Keras\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D,MaxPooling1D,Flatten,BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.metrics import Precision, Recall\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvNj7wSB1r53"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pvnxmBrt7gd",
        "outputId": "dfeb2067-b288-4421-81e3-a1793a0eebb5"
      },
      "source": [
        "#Import data\n",
        "x_train = pd.read_csv(\"data/X_train_features.csv\", index_col=0, header=0, low_memory=False)\n",
        "y_train = pd.read_csv(\"data/y_train.csv\", index_col=0, header=0)\n",
        "x_test = pd.read_csv(\"data/X_test_features.csv\", index_col=0, header=0, low_memory=False)\n",
        "#Only take time avg. segment\n",
        "normal_features=x_train.iloc[:,57:]\n",
        "\n",
        "#only try easier problem\n",
        "print(normal_features.shape)\n",
        "normal_features=normal_features[y_train['y']<3]\n",
        "print(normal_features.shape)\n",
        "y_tr=y_train[y_train['y']<3]\n",
        "\n",
        "#Imputer and scaler\n",
        "imputer = SimpleImputer()\n",
        "scaler = StandardScaler()\n",
        "features=imputer.fit_transform(normal_features)\n",
        "selected=scaler.fit_transform(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5117, 1820)\n",
            "(4947, 1820)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V3YHLGb20N1"
      },
      "source": [
        "### Prepare data for CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSoE9k-U7XMf"
      },
      "source": [
        "stacked=[]\n",
        "length=180\n",
        "for row in range(len(selected)):\n",
        "  current_row=[]\n",
        "  for time in range(length):\n",
        "    current_signal=[]\n",
        "    for feature in range(5):\n",
        "      current_signal.append(selected[row,57+feature*length+time])\n",
        "    current_row.append(current_signal)\n",
        "  stacked.append(current_row)\n",
        "stacked=np.array(stacked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnNI6FJu2vvG"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIoTab1W2akv"
      },
      "source": [
        "### Different losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnyKZQlubzPW"
      },
      "source": [
        "# different loss for Keras to optimize, performed worse than categorical_crossentropy\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    #f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    \n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    #f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return 1 - K.mean(f1)\n",
        "    \n",
        "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
        "    \"\"\"\n",
        "    Implementation of Focal Loss from the paper in multiclass classification\n",
        "    Formula:\n",
        "        loss = -alpha*((1-p)^gamma)*log(p)\n",
        "    Parameters:\n",
        "        alpha -- the same as wighting factor in balanced cross entropy\n",
        "        gamma -- focusing parameter for modulating factor (1-p)\n",
        "    Default value:\n",
        "        gamma -- 2.0 as mentioned in the paper\n",
        "        alpha -- 0.25 as mentioned in the paper\n",
        "    \"\"\"\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        # Define epsilon so that the backpropagation will not result in NaN\n",
        "        # for 0 divisor case\n",
        "        epsilon = K.epsilon()\n",
        "        # Add the epsilon to prediction value\n",
        "        #y_pred = y_pred + epsilon\n",
        "        # Clip the prediction value\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
        "        # Calculate cross entropy\n",
        "        cross_entropy = -y_true*K.log(y_pred)\n",
        "        # Calculate weight that consists of  modulating factor and weighting factor\n",
        "        weight = alpha * y_true * K.pow((1-y_pred), gamma)\n",
        "        # Calculate focal loss\n",
        "        loss = weight * cross_entropy\n",
        "        # Sum the losses in mini_batch\n",
        "        loss = K.sum(loss, axis=1)\n",
        "        return loss\n",
        "    \n",
        "    return focal_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp854RIg3D4l"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_12uNkMpSuQ"
      },
      "source": [
        "# adjusted those params\n",
        "input_dim=180\n",
        "dropout=0.2\n",
        "def get_model():\n",
        "\t# create model\n",
        "  model = Sequential()\n",
        "  # Normalization on and off tried\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(input_dim, activation='selu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(input_dim, activation='selu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(input_dim, activation='selu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[Precision(), Recall()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTjBZ9Pi3G3M"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6o4K7cQrvbF",
        "outputId": "4b99f07b-2cea-4e59-cf03-6404e3e49605"
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y_tr)\n",
        "skf=StratifiedKFold(n_splits=5)\n",
        "for train_index,test_index in skf.split(selected,y_tr):\n",
        "  X_train = selected[train_index]\n",
        "  X_test = selected[test_index]\n",
        "  Y_train = enc.transform(y_tr.iloc[train_index]).toarray()\n",
        "  Y_test = y_tr.iloc[test_index]\n",
        "  model = get_model()\n",
        "  early = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", patience=20, verbose=1)\n",
        "  redonplat = ReduceLROnPlateau(monitor=\"val_loss\", mode=\"auto\", patience=10, verbose=2)\n",
        "  callbacks_list = [early, redonplat]  # early\n",
        "  model.fit(X_train, Y_train, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "  model.summary()\n",
        "  Y_pred=enc.inverse_transform(model.predict(X_test))\n",
        "  print(confusion_matrix(Y_test, Y_pred))\n",
        "  print('Score')\n",
        "  print(f1_score(Y_test, Y_pred, average='micro'))\n",
        "  print()\n",
        "  print()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "112/112 - 1s - loss: 1.3844 - precision_95: 0.5851 - recall_95: 0.5636 - val_loss: 0.7921 - val_precision_95: 0.7049 - val_recall_95: 0.6515\n",
            "Epoch 2/1000\n",
            "112/112 - 1s - loss: 1.0713 - precision_95: 0.6219 - recall_95: 0.5922 - val_loss: 0.6842 - val_precision_95: 0.7127 - val_recall_95: 0.6515\n",
            "Epoch 3/1000\n",
            "112/112 - 0s - loss: 0.9307 - precision_95: 0.6580 - recall_95: 0.6170 - val_loss: 0.6810 - val_precision_95: 0.7352 - val_recall_95: 0.6591\n",
            "Epoch 4/1000\n",
            "112/112 - 1s - loss: 0.8225 - precision_95: 0.6756 - recall_95: 0.6347 - val_loss: 0.6701 - val_precision_95: 0.7345 - val_recall_95: 0.6566\n",
            "Epoch 5/1000\n",
            "112/112 - 0s - loss: 0.7360 - precision_95: 0.6965 - recall_95: 0.6549 - val_loss: 0.7071 - val_precision_95: 0.7095 - val_recall_95: 0.6414\n",
            "Epoch 6/1000\n",
            "112/112 - 0s - loss: 0.6971 - precision_95: 0.7151 - recall_95: 0.6723 - val_loss: 0.6742 - val_precision_95: 0.7258 - val_recall_95: 0.6818\n",
            "Epoch 7/1000\n",
            "112/112 - 0s - loss: 0.6642 - precision_95: 0.7174 - recall_95: 0.6787 - val_loss: 0.6179 - val_precision_95: 0.7421 - val_recall_95: 0.7121\n",
            "Epoch 8/1000\n",
            "112/112 - 0s - loss: 0.6326 - precision_95: 0.7400 - recall_95: 0.6889 - val_loss: 0.6583 - val_precision_95: 0.7313 - val_recall_95: 0.6667\n",
            "Epoch 9/1000\n",
            "112/112 - 0s - loss: 0.6137 - precision_95: 0.7528 - recall_95: 0.7124 - val_loss: 0.6360 - val_precision_95: 0.7310 - val_recall_95: 0.6793\n",
            "Epoch 10/1000\n",
            "112/112 - 0s - loss: 0.5875 - precision_95: 0.7551 - recall_95: 0.7119 - val_loss: 0.6534 - val_precision_95: 0.7258 - val_recall_95: 0.6818\n",
            "Epoch 11/1000\n",
            "112/112 - 0s - loss: 0.5900 - precision_95: 0.7571 - recall_95: 0.7169 - val_loss: 0.6101 - val_precision_95: 0.7394 - val_recall_95: 0.7020\n",
            "Epoch 12/1000\n",
            "112/112 - 0s - loss: 0.5744 - precision_95: 0.7625 - recall_95: 0.7276 - val_loss: 0.6741 - val_precision_95: 0.7213 - val_recall_95: 0.6667\n",
            "Epoch 13/1000\n",
            "112/112 - 0s - loss: 0.5535 - precision_95: 0.7811 - recall_95: 0.7386 - val_loss: 0.6468 - val_precision_95: 0.7614 - val_recall_95: 0.7172\n",
            "Epoch 14/1000\n",
            "112/112 - 0s - loss: 0.5658 - precision_95: 0.7750 - recall_95: 0.7265 - val_loss: 0.6335 - val_precision_95: 0.7385 - val_recall_95: 0.6919\n",
            "Epoch 15/1000\n",
            "112/112 - 0s - loss: 0.5331 - precision_95: 0.7802 - recall_95: 0.7456 - val_loss: 0.6704 - val_precision_95: 0.7339 - val_recall_95: 0.6894\n",
            "Epoch 16/1000\n",
            "112/112 - 0s - loss: 0.5273 - precision_95: 0.7926 - recall_95: 0.7546 - val_loss: 0.6488 - val_precision_95: 0.7328 - val_recall_95: 0.6995\n",
            "Epoch 17/1000\n",
            "112/112 - 0s - loss: 0.5217 - precision_95: 0.7898 - recall_95: 0.7532 - val_loss: 0.6594 - val_precision_95: 0.7321 - val_recall_95: 0.6970\n",
            "Epoch 18/1000\n",
            "112/112 - 0s - loss: 0.5234 - precision_95: 0.7823 - recall_95: 0.7518 - val_loss: 0.6702 - val_precision_95: 0.7374 - val_recall_95: 0.7020\n",
            "Epoch 19/1000\n",
            "112/112 - 0s - loss: 0.5125 - precision_95: 0.7909 - recall_95: 0.7596 - val_loss: 0.6235 - val_precision_95: 0.7588 - val_recall_95: 0.7071\n",
            "Epoch 20/1000\n",
            "112/112 - 0s - loss: 0.4796 - precision_95: 0.8108 - recall_95: 0.7835 - val_loss: 0.7061 - val_precision_95: 0.7174 - val_recall_95: 0.6667\n",
            "Epoch 21/1000\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "112/112 - 0s - loss: 0.4814 - precision_95: 0.8013 - recall_95: 0.7725 - val_loss: 0.6770 - val_precision_95: 0.7324 - val_recall_95: 0.6843\n",
            "Epoch 22/1000\n",
            "112/112 - 0s - loss: 0.4208 - precision_95: 0.8363 - recall_95: 0.8062 - val_loss: 0.6666 - val_precision_95: 0.7447 - val_recall_95: 0.7146\n",
            "Epoch 23/1000\n",
            "112/112 - 0s - loss: 0.3973 - precision_95: 0.8493 - recall_95: 0.8200 - val_loss: 0.6687 - val_precision_95: 0.7277 - val_recall_95: 0.7020\n",
            "Epoch 24/1000\n",
            "112/112 - 0s - loss: 0.4015 - precision_95: 0.8438 - recall_95: 0.8189 - val_loss: 0.6638 - val_precision_95: 0.7441 - val_recall_95: 0.7121\n",
            "Epoch 25/1000\n",
            "112/112 - 0s - loss: 0.4046 - precision_95: 0.8381 - recall_95: 0.8141 - val_loss: 0.6780 - val_precision_95: 0.7256 - val_recall_95: 0.6944\n",
            "Epoch 26/1000\n",
            "112/112 - 0s - loss: 0.3952 - precision_95: 0.8463 - recall_95: 0.8225 - val_loss: 0.6818 - val_precision_95: 0.7277 - val_recall_95: 0.7020\n",
            "Epoch 27/1000\n",
            "112/112 - 1s - loss: 0.3839 - precision_95: 0.8453 - recall_95: 0.8225 - val_loss: 0.6915 - val_precision_95: 0.7277 - val_recall_95: 0.7020\n",
            "Epoch 28/1000\n",
            "112/112 - 1s - loss: 0.3837 - precision_95: 0.8458 - recall_95: 0.8256 - val_loss: 0.6851 - val_precision_95: 0.7325 - val_recall_95: 0.7121\n",
            "Epoch 29/1000\n",
            "112/112 - 0s - loss: 0.3858 - precision_95: 0.8502 - recall_95: 0.8273 - val_loss: 0.7033 - val_precision_95: 0.7161 - val_recall_95: 0.6944\n",
            "Epoch 30/1000\n",
            "112/112 - 1s - loss: 0.3653 - precision_95: 0.8521 - recall_95: 0.8315 - val_loss: 0.7103 - val_precision_95: 0.7258 - val_recall_95: 0.7020\n",
            "Epoch 31/1000\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "112/112 - 0s - loss: 0.3679 - precision_95: 0.8566 - recall_95: 0.8368 - val_loss: 0.7124 - val_precision_95: 0.7202 - val_recall_95: 0.7020\n",
            "Epoch 00031: early stopping\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 1820)              7280      \n",
            "_________________________________________________________________\n",
            "dropout_380 (Dropout)        (None, 1820)              0         \n",
            "_________________________________________________________________\n",
            "dense_350 (Dense)            (None, 180)               327780    \n",
            "_________________________________________________________________\n",
            "dropout_381 (Dropout)        (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense_351 (Dense)            (None, 180)               32580     \n",
            "_________________________________________________________________\n",
            "dropout_382 (Dropout)        (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense_352 (Dense)            (None, 180)               32580     \n",
            "_________________________________________________________________\n",
            "dropout_383 (Dropout)        (None, 180)               0         \n",
            "_________________________________________________________________\n",
            "dense_353 (Dense)            (None, 3)                 543       \n",
            "=================================================================\n",
            "Total params: 400,763\n",
            "Trainable params: 397,123\n",
            "Non-trainable params: 3,640\n",
            "_________________________________________________________________\n",
            "[[525  16  65]\n",
            " [ 11  59  19]\n",
            " [133  19 143]]\n",
            "Score\n",
            "0.7343434343434343\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX2VSM5-3MHr"
      },
      "source": [
        "### Create model with bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrybls_3V5i"
      },
      "source": [
        "#played with those params, filter, kernel size, and amount of dense layers at the end\n",
        "input_dim=256\n",
        "dropout=0.1\n",
        "def get_bottle():\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv1D(64, 3, activation='selu', input_shape=(180, 5)))\n",
        "  model.add(MaxPooling1D(3))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Conv1D(64, 3, activation='selu'))\n",
        "  model.add(MaxPooling1D(3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(input_dim, activation='selu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(input_dim/2, activation='selu'))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[Precision(), Recall()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2YIllCw3Wrw"
      },
      "source": [
        "### Train model with bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLm3x5yNEvuL",
        "outputId": "60afeb71-a892-42a5-ca3f-ef094fcf1874"
      },
      "source": [
        "skf=StratifiedKFold(n_splits=5)\n",
        "for train_index,test_index in skf.split(stacked,y_tr):\n",
        "  X_train = stacked[train_index]\n",
        "  X_test = stacked[test_index]\n",
        "  Y_train = enc.transform(y_tr.iloc[train_index]).toarray()\n",
        "  Y_test = y_tr.iloc[test_index]\n",
        "  model = get_bottle()\n",
        "  early = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", patience=20, verbose=1)\n",
        "  redonplat = ReduceLROnPlateau(monitor=\"val_loss\", mode=\"auto\", patience=10, verbose=2)\n",
        "  callbacks_list = [early, redonplat]  # early\n",
        "\n",
        "  model.fit(X_train, Y_train,batch_size=len(X_train), epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "  Y_pred=enc.inverse_transform(model.predict(X_test))\n",
        "  print('Score')\n",
        "  print(f1_score(Y_test, Y_pred, average='micro'))\n",
        "  print()\n",
        "  print()\n",
        "  model.summary()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 - 0s - loss: 1.6701 - precision_105: 0.2282 - recall_105: 0.1733 - val_loss: 1.2485 - val_precision_105: 0.5833 - val_recall_105: 0.5657\n",
            "Epoch 2/1000\n",
            "1/1 - 0s - loss: 1.2422 - precision_105: 0.5823 - recall_105: 0.5673 - val_loss: 1.1172 - val_precision_105: 0.6343 - val_recall_105: 0.6263\n",
            "Epoch 3/1000\n",
            "1/1 - 0s - loss: 1.2315 - precision_105: 0.6402 - recall_105: 0.6327 - val_loss: 0.9880 - val_precision_105: 0.6451 - val_recall_105: 0.6288\n",
            "Epoch 4/1000\n",
            "1/1 - 0s - loss: 1.1756 - precision_105: 0.6261 - recall_105: 0.6192 - val_loss: 0.8770 - val_precision_105: 0.6736 - val_recall_105: 0.6515\n",
            "Epoch 5/1000\n",
            "1/1 - 0s - loss: 1.0858 - precision_105: 0.6216 - recall_105: 0.6122 - val_loss: 0.8283 - val_precision_105: 0.6841 - val_recall_105: 0.6616\n",
            "Epoch 6/1000\n",
            "1/1 - 0s - loss: 0.9954 - precision_105: 0.6385 - recall_105: 0.6240 - val_loss: 0.8062 - val_precision_105: 0.6684 - val_recall_105: 0.6313\n",
            "Epoch 7/1000\n",
            "1/1 - 0s - loss: 0.9213 - precision_105: 0.6639 - recall_105: 0.6400 - val_loss: 0.7965 - val_precision_105: 0.7025 - val_recall_105: 0.6439\n",
            "Epoch 8/1000\n",
            "1/1 - 0s - loss: 0.8503 - precision_105: 0.6827 - recall_105: 0.6459 - val_loss: 0.7993 - val_precision_105: 0.6958 - val_recall_105: 0.6237\n",
            "Epoch 9/1000\n",
            "1/1 - 0s - loss: 0.8220 - precision_105: 0.6837 - recall_105: 0.6332 - val_loss: 0.8169 - val_precision_105: 0.6705 - val_recall_105: 0.5909\n",
            "Epoch 10/1000\n",
            "1/1 - 0s - loss: 0.8029 - precision_105: 0.6840 - recall_105: 0.6259 - val_loss: 0.8204 - val_precision_105: 0.6461 - val_recall_105: 0.5808\n",
            "Epoch 11/1000\n",
            "1/1 - 0s - loss: 0.8061 - precision_105: 0.6734 - recall_105: 0.6091 - val_loss: 0.7960 - val_precision_105: 0.6620 - val_recall_105: 0.5934\n",
            "Epoch 12/1000\n",
            "1/1 - 0s - loss: 0.7753 - precision_105: 0.6811 - recall_105: 0.6099 - val_loss: 0.7625 - val_precision_105: 0.6850 - val_recall_105: 0.5985\n",
            "Epoch 13/1000\n",
            "1/1 - 0s - loss: 0.7532 - precision_105: 0.6997 - recall_105: 0.6198 - val_loss: 0.7369 - val_precision_105: 0.7225 - val_recall_105: 0.6313\n",
            "Epoch 14/1000\n",
            "1/1 - 0s - loss: 0.7312 - precision_105: 0.7131 - recall_105: 0.6324 - val_loss: 0.7197 - val_precision_105: 0.7300 - val_recall_105: 0.6212\n",
            "Epoch 15/1000\n",
            "1/1 - 0s - loss: 0.7217 - precision_105: 0.7171 - recall_105: 0.6377 - val_loss: 0.7067 - val_precision_105: 0.7447 - val_recall_105: 0.6263\n",
            "Epoch 16/1000\n",
            "1/1 - 0s - loss: 0.7176 - precision_105: 0.7214 - recall_105: 0.6420 - val_loss: 0.6964 - val_precision_105: 0.7538 - val_recall_105: 0.6263\n",
            "Epoch 17/1000\n",
            "1/1 - 0s - loss: 0.7087 - precision_105: 0.7209 - recall_105: 0.6425 - val_loss: 0.6915 - val_precision_105: 0.7631 - val_recall_105: 0.6263\n",
            "Epoch 18/1000\n",
            "1/1 - 0s - loss: 0.7168 - precision_105: 0.7108 - recall_105: 0.6372 - val_loss: 0.6863 - val_precision_105: 0.7692 - val_recall_105: 0.6313\n",
            "Epoch 19/1000\n",
            "1/1 - 0s - loss: 0.7088 - precision_105: 0.7184 - recall_105: 0.6442 - val_loss: 0.6758 - val_precision_105: 0.7708 - val_recall_105: 0.6540\n",
            "Epoch 20/1000\n",
            "1/1 - 0s - loss: 0.7060 - precision_105: 0.7108 - recall_105: 0.6501 - val_loss: 0.6657 - val_precision_105: 0.7595 - val_recall_105: 0.6540\n",
            "Epoch 21/1000\n",
            "1/1 - 0s - loss: 0.6954 - precision_105: 0.7262 - recall_105: 0.6563 - val_loss: 0.6597 - val_precision_105: 0.7558 - val_recall_105: 0.6566\n",
            "Epoch 22/1000\n",
            "1/1 - 0s - loss: 0.6916 - precision_105: 0.7256 - recall_105: 0.6594 - val_loss: 0.6556 - val_precision_105: 0.7515 - val_recall_105: 0.6490\n",
            "Epoch 23/1000\n",
            "1/1 - 0s - loss: 0.6726 - precision_105: 0.7277 - recall_105: 0.6627 - val_loss: 0.6525 - val_precision_105: 0.7623 - val_recall_105: 0.6641\n",
            "Epoch 24/1000\n",
            "1/1 - 0s - loss: 0.6687 - precision_105: 0.7336 - recall_105: 0.6728 - val_loss: 0.6538 - val_precision_105: 0.7637 - val_recall_105: 0.6692\n",
            "Epoch 25/1000\n",
            "1/1 - 0s - loss: 0.6647 - precision_105: 0.7450 - recall_105: 0.6720 - val_loss: 0.6592 - val_precision_105: 0.7580 - val_recall_105: 0.6566\n",
            "Epoch 26/1000\n",
            "1/1 - 0s - loss: 0.6611 - precision_105: 0.7449 - recall_105: 0.6658 - val_loss: 0.6646 - val_precision_105: 0.7544 - val_recall_105: 0.6515\n",
            "Epoch 27/1000\n",
            "1/1 - 0s - loss: 0.6661 - precision_105: 0.7455 - recall_105: 0.6655 - val_loss: 0.6654 - val_precision_105: 0.7544 - val_recall_105: 0.6515\n",
            "Epoch 28/1000\n",
            "1/1 - 0s - loss: 0.6525 - precision_105: 0.7393 - recall_105: 0.6641 - val_loss: 0.6625 - val_precision_105: 0.7565 - val_recall_105: 0.6591\n",
            "Epoch 29/1000\n",
            "1/1 - 0s - loss: 0.6583 - precision_105: 0.7517 - recall_105: 0.6776 - val_loss: 0.6587 - val_precision_105: 0.7557 - val_recall_105: 0.6717\n",
            "Epoch 30/1000\n",
            "1/1 - 0s - loss: 0.6479 - precision_105: 0.7496 - recall_105: 0.6776 - val_loss: 0.6544 - val_precision_105: 0.7507 - val_recall_105: 0.6768\n",
            "Epoch 31/1000\n",
            "1/1 - 0s - loss: 0.6527 - precision_105: 0.7462 - recall_105: 0.6787 - val_loss: 0.6495 - val_precision_105: 0.7571 - val_recall_105: 0.6768\n",
            "Epoch 32/1000\n",
            "1/1 - 0s - loss: 0.6356 - precision_105: 0.7505 - recall_105: 0.6869 - val_loss: 0.6450 - val_precision_105: 0.7564 - val_recall_105: 0.6742\n",
            "Epoch 33/1000\n",
            "1/1 - 0s - loss: 0.6366 - precision_105: 0.7396 - recall_105: 0.6852 - val_loss: 0.6418 - val_precision_105: 0.7528 - val_recall_105: 0.6692\n",
            "Epoch 34/1000\n",
            "1/1 - 0s - loss: 0.6362 - precision_105: 0.7509 - recall_105: 0.6908 - val_loss: 0.6385 - val_precision_105: 0.7521 - val_recall_105: 0.6667\n",
            "Epoch 35/1000\n",
            "1/1 - 0s - loss: 0.6317 - precision_105: 0.7476 - recall_105: 0.6877 - val_loss: 0.6361 - val_precision_105: 0.7564 - val_recall_105: 0.6667\n",
            "Epoch 36/1000\n",
            "1/1 - 0s - loss: 0.6255 - precision_105: 0.7450 - recall_105: 0.6858 - val_loss: 0.6353 - val_precision_105: 0.7557 - val_recall_105: 0.6717\n",
            "Epoch 37/1000\n",
            "1/1 - 0s - loss: 0.6266 - precision_105: 0.7526 - recall_105: 0.6981 - val_loss: 0.6363 - val_precision_105: 0.7528 - val_recall_105: 0.6768\n",
            "Epoch 38/1000\n",
            "1/1 - 0s - loss: 0.6307 - precision_105: 0.7460 - recall_105: 0.6880 - val_loss: 0.6370 - val_precision_105: 0.7486 - val_recall_105: 0.6692\n",
            "Epoch 39/1000\n",
            "1/1 - 0s - loss: 0.6278 - precision_105: 0.7516 - recall_105: 0.6917 - val_loss: 0.6388 - val_precision_105: 0.7557 - val_recall_105: 0.6717\n",
            "Epoch 40/1000\n",
            "1/1 - 0s - loss: 0.6282 - precision_105: 0.7495 - recall_105: 0.6891 - val_loss: 0.6405 - val_precision_105: 0.7571 - val_recall_105: 0.6692\n",
            "Epoch 41/1000\n",
            "1/1 - 0s - loss: 0.6228 - precision_105: 0.7473 - recall_105: 0.6894 - val_loss: 0.6410 - val_precision_105: 0.7521 - val_recall_105: 0.6742\n",
            "Epoch 42/1000\n",
            "1/1 - 0s - loss: 0.6142 - precision_105: 0.7563 - recall_105: 0.6928 - val_loss: 0.6406 - val_precision_105: 0.7458 - val_recall_105: 0.6742\n",
            "Epoch 43/1000\n",
            "1/1 - 0s - loss: 0.6160 - precision_105: 0.7521 - recall_105: 0.6917 - val_loss: 0.6393 - val_precision_105: 0.7472 - val_recall_105: 0.6717\n",
            "Epoch 44/1000\n",
            "1/1 - 0s - loss: 0.6099 - precision_105: 0.7580 - recall_105: 0.6947 - val_loss: 0.6371 - val_precision_105: 0.7528 - val_recall_105: 0.6692\n",
            "Epoch 45/1000\n",
            "1/1 - 0s - loss: 0.6067 - precision_105: 0.7645 - recall_105: 0.6936 - val_loss: 0.6339 - val_precision_105: 0.7549 - val_recall_105: 0.6768\n",
            "Epoch 46/1000\n",
            "1/1 - 0s - loss: 0.6062 - precision_105: 0.7656 - recall_105: 0.7043 - val_loss: 0.6302 - val_precision_105: 0.7642 - val_recall_105: 0.6793\n",
            "Epoch 47/1000\n",
            "1/1 - 0s - loss: 0.6039 - precision_105: 0.7621 - recall_105: 0.6998 - val_loss: 0.6251 - val_precision_105: 0.7708 - val_recall_105: 0.6793\n",
            "Epoch 48/1000\n",
            "1/1 - 0s - loss: 0.5954 - precision_105: 0.7685 - recall_105: 0.7057 - val_loss: 0.6191 - val_precision_105: 0.7708 - val_recall_105: 0.6793\n",
            "Epoch 49/1000\n",
            "1/1 - 0s - loss: 0.6071 - precision_105: 0.7595 - recall_105: 0.7023 - val_loss: 0.6142 - val_precision_105: 0.7692 - val_recall_105: 0.6818\n",
            "Epoch 50/1000\n",
            "1/1 - 0s - loss: 0.5909 - precision_105: 0.7675 - recall_105: 0.7099 - val_loss: 0.6121 - val_precision_105: 0.7619 - val_recall_105: 0.6869\n",
            "Epoch 51/1000\n",
            "1/1 - 0s - loss: 0.6025 - precision_105: 0.7635 - recall_105: 0.7051 - val_loss: 0.6103 - val_precision_105: 0.7591 - val_recall_105: 0.6843\n",
            "Epoch 52/1000\n",
            "1/1 - 0s - loss: 0.5844 - precision_105: 0.7715 - recall_105: 0.7169 - val_loss: 0.6103 - val_precision_105: 0.7655 - val_recall_105: 0.6843\n",
            "Epoch 53/1000\n",
            "1/1 - 0s - loss: 0.5825 - precision_105: 0.7708 - recall_105: 0.7158 - val_loss: 0.6110 - val_precision_105: 0.7705 - val_recall_105: 0.6869\n",
            "Epoch 54/1000\n",
            "1/1 - 0s - loss: 0.5908 - precision_105: 0.7716 - recall_105: 0.7133 - val_loss: 0.6089 - val_precision_105: 0.7664 - val_recall_105: 0.6793\n",
            "Epoch 55/1000\n",
            "1/1 - 0s - loss: 0.5907 - precision_105: 0.7665 - recall_105: 0.7091 - val_loss: 0.6079 - val_precision_105: 0.7635 - val_recall_105: 0.6768\n",
            "Epoch 56/1000\n",
            "1/1 - 0s - loss: 0.5898 - precision_105: 0.7658 - recall_105: 0.7133 - val_loss: 0.6070 - val_precision_105: 0.7684 - val_recall_105: 0.6869\n",
            "Epoch 57/1000\n",
            "1/1 - 0s - loss: 0.5829 - precision_105: 0.7769 - recall_105: 0.7186 - val_loss: 0.6066 - val_precision_105: 0.7746 - val_recall_105: 0.6944\n",
            "Epoch 58/1000\n",
            "1/1 - 0s - loss: 0.5889 - precision_105: 0.7616 - recall_105: 0.7079 - val_loss: 0.6067 - val_precision_105: 0.7765 - val_recall_105: 0.7020\n",
            "Epoch 59/1000\n",
            "1/1 - 0s - loss: 0.5823 - precision_105: 0.7707 - recall_105: 0.7096 - val_loss: 0.6061 - val_precision_105: 0.7712 - val_recall_105: 0.6894\n",
            "Epoch 60/1000\n",
            "1/1 - 0s - loss: 0.5840 - precision_105: 0.7718 - recall_105: 0.7124 - val_loss: 0.6048 - val_precision_105: 0.7647 - val_recall_105: 0.6894\n",
            "Epoch 61/1000\n",
            "1/1 - 0s - loss: 0.5772 - precision_105: 0.7768 - recall_105: 0.7211 - val_loss: 0.6032 - val_precision_105: 0.7640 - val_recall_105: 0.6869\n",
            "Epoch 62/1000\n",
            "1/1 - 0s - loss: 0.5701 - precision_105: 0.7745 - recall_105: 0.7178 - val_loss: 0.6004 - val_precision_105: 0.7718 - val_recall_105: 0.6919\n",
            "Epoch 63/1000\n",
            "1/1 - 0s - loss: 0.5807 - precision_105: 0.7704 - recall_105: 0.7133 - val_loss: 0.5980 - val_precision_105: 0.7688 - val_recall_105: 0.6970\n",
            "Epoch 64/1000\n",
            "1/1 - 0s - loss: 0.5751 - precision_105: 0.7750 - recall_105: 0.7178 - val_loss: 0.5937 - val_precision_105: 0.7722 - val_recall_105: 0.7020\n",
            "Epoch 65/1000\n",
            "1/1 - 0s - loss: 0.5667 - precision_105: 0.7765 - recall_105: 0.7172 - val_loss: 0.5900 - val_precision_105: 0.7750 - val_recall_105: 0.7045\n",
            "Epoch 66/1000\n",
            "1/1 - 0s - loss: 0.5695 - precision_105: 0.7695 - recall_105: 0.7144 - val_loss: 0.5885 - val_precision_105: 0.7722 - val_recall_105: 0.7020\n",
            "Epoch 67/1000\n",
            "1/1 - 0s - loss: 0.5629 - precision_105: 0.7794 - recall_105: 0.7293 - val_loss: 0.5898 - val_precision_105: 0.7756 - val_recall_105: 0.7071\n",
            "Epoch 68/1000\n",
            "1/1 - 0s - loss: 0.5627 - precision_105: 0.7845 - recall_105: 0.7290 - val_loss: 0.5907 - val_precision_105: 0.7762 - val_recall_105: 0.7096\n",
            "Epoch 69/1000\n",
            "1/1 - 0s - loss: 0.5719 - precision_105: 0.7765 - recall_105: 0.7268 - val_loss: 0.5909 - val_precision_105: 0.7741 - val_recall_105: 0.7096\n",
            "Epoch 70/1000\n",
            "1/1 - 0s - loss: 0.5593 - precision_105: 0.7858 - recall_105: 0.7335 - val_loss: 0.5897 - val_precision_105: 0.7663 - val_recall_105: 0.7121\n",
            "Epoch 71/1000\n",
            "1/1 - 0s - loss: 0.5565 - precision_105: 0.7826 - recall_105: 0.7310 - val_loss: 0.5883 - val_precision_105: 0.7684 - val_recall_105: 0.7121\n",
            "Epoch 72/1000\n",
            "1/1 - 0s - loss: 0.5546 - precision_105: 0.7762 - recall_105: 0.7209 - val_loss: 0.5871 - val_precision_105: 0.7711 - val_recall_105: 0.7146\n",
            "Epoch 73/1000\n",
            "1/1 - 0s - loss: 0.5570 - precision_105: 0.7735 - recall_105: 0.7231 - val_loss: 0.5877 - val_precision_105: 0.7760 - val_recall_105: 0.7172\n",
            "Epoch 74/1000\n",
            "1/1 - 0s - loss: 0.5434 - precision_105: 0.7847 - recall_105: 0.7307 - val_loss: 0.5888 - val_precision_105: 0.7747 - val_recall_105: 0.7121\n",
            "Epoch 75/1000\n",
            "1/1 - 0s - loss: 0.5388 - precision_105: 0.7813 - recall_105: 0.7352 - val_loss: 0.5872 - val_precision_105: 0.7732 - val_recall_105: 0.7146\n",
            "Epoch 76/1000\n",
            "1/1 - 0s - loss: 0.5487 - precision_105: 0.7793 - recall_105: 0.7270 - val_loss: 0.5846 - val_precision_105: 0.7690 - val_recall_105: 0.7146\n",
            "Epoch 77/1000\n",
            "1/1 - 0s - loss: 0.5526 - precision_105: 0.7810 - recall_105: 0.7349 - val_loss: 0.5832 - val_precision_105: 0.7684 - val_recall_105: 0.7121\n",
            "Epoch 78/1000\n",
            "1/1 - 0s - loss: 0.5420 - precision_105: 0.7831 - recall_105: 0.7318 - val_loss: 0.5836 - val_precision_105: 0.7692 - val_recall_105: 0.7071\n",
            "Epoch 79/1000\n",
            "1/1 - 0s - loss: 0.5419 - precision_105: 0.7908 - recall_105: 0.7357 - val_loss: 0.5844 - val_precision_105: 0.7711 - val_recall_105: 0.7146\n",
            "Epoch 80/1000\n",
            "1/1 - 0s - loss: 0.5437 - precision_105: 0.7872 - recall_105: 0.7363 - val_loss: 0.5843 - val_precision_105: 0.7684 - val_recall_105: 0.7121\n",
            "Epoch 81/1000\n",
            "1/1 - 0s - loss: 0.5477 - precision_105: 0.7832 - recall_105: 0.7335 - val_loss: 0.5843 - val_precision_105: 0.7636 - val_recall_105: 0.7096\n",
            "Epoch 82/1000\n",
            "1/1 - 0s - loss: 0.5353 - precision_105: 0.7915 - recall_105: 0.7408 - val_loss: 0.5828 - val_precision_105: 0.7671 - val_recall_105: 0.7071\n",
            "Epoch 83/1000\n",
            "1/1 - 0s - loss: 0.5395 - precision_105: 0.7915 - recall_105: 0.7439 - val_loss: 0.5823 - val_precision_105: 0.7726 - val_recall_105: 0.7121\n",
            "Epoch 84/1000\n",
            "1/1 - 0s - loss: 0.5441 - precision_105: 0.7826 - recall_105: 0.7321 - val_loss: 0.5805 - val_precision_105: 0.7703 - val_recall_105: 0.7197\n",
            "Epoch 85/1000\n",
            "1/1 - 0s - loss: 0.5436 - precision_105: 0.7887 - recall_105: 0.7422 - val_loss: 0.5768 - val_precision_105: 0.7721 - val_recall_105: 0.7273\n",
            "Epoch 86/1000\n",
            "1/1 - 0s - loss: 0.5296 - precision_105: 0.7902 - recall_105: 0.7436 - val_loss: 0.5746 - val_precision_105: 0.7715 - val_recall_105: 0.7247\n",
            "Epoch 87/1000\n",
            "1/1 - 0s - loss: 0.5326 - precision_105: 0.7891 - recall_105: 0.7473 - val_loss: 0.5740 - val_precision_105: 0.7701 - val_recall_105: 0.7273\n",
            "Epoch 88/1000\n",
            "1/1 - 0s - loss: 0.5378 - precision_105: 0.7954 - recall_105: 0.7489 - val_loss: 0.5756 - val_precision_105: 0.7668 - val_recall_105: 0.7222\n",
            "Epoch 89/1000\n",
            "1/1 - 0s - loss: 0.5318 - precision_105: 0.7938 - recall_105: 0.7461 - val_loss: 0.5768 - val_precision_105: 0.7641 - val_recall_105: 0.7197\n",
            "Epoch 90/1000\n",
            "1/1 - 0s - loss: 0.5311 - precision_105: 0.7866 - recall_105: 0.7402 - val_loss: 0.5775 - val_precision_105: 0.7642 - val_recall_105: 0.7121\n",
            "Epoch 91/1000\n",
            "1/1 - 0s - loss: 0.5275 - precision_105: 0.7909 - recall_105: 0.7445 - val_loss: 0.5763 - val_precision_105: 0.7707 - val_recall_105: 0.7298\n",
            "Epoch 92/1000\n",
            "1/1 - 0s - loss: 0.5274 - precision_105: 0.7896 - recall_105: 0.7419 - val_loss: 0.5784 - val_precision_105: 0.7715 - val_recall_105: 0.7247\n",
            "Epoch 93/1000\n",
            "1/1 - 0s - loss: 0.5318 - precision_105: 0.7880 - recall_105: 0.7445 - val_loss: 0.5774 - val_precision_105: 0.7701 - val_recall_105: 0.7273\n",
            "Epoch 94/1000\n",
            "1/1 - 0s - loss: 0.5150 - precision_105: 0.7953 - recall_105: 0.7529 - val_loss: 0.5745 - val_precision_105: 0.7688 - val_recall_105: 0.7222\n",
            "Epoch 95/1000\n",
            "1/1 - 0s - loss: 0.5273 - precision_105: 0.7918 - recall_105: 0.7475 - val_loss: 0.5717 - val_precision_105: 0.7653 - val_recall_105: 0.7247\n",
            "Epoch 96/1000\n",
            "1/1 - 0s - loss: 0.5191 - precision_105: 0.7949 - recall_105: 0.7498 - val_loss: 0.5699 - val_precision_105: 0.7772 - val_recall_105: 0.7222\n",
            "Epoch 97/1000\n",
            "1/1 - 0s - loss: 0.5132 - precision_105: 0.7986 - recall_105: 0.7537 - val_loss: 0.5718 - val_precision_105: 0.7805 - val_recall_105: 0.7273\n",
            "Epoch 98/1000\n",
            "1/1 - 0s - loss: 0.5163 - precision_105: 0.7984 - recall_105: 0.7551 - val_loss: 0.5763 - val_precision_105: 0.7715 - val_recall_105: 0.7247\n",
            "Epoch 99/1000\n",
            "1/1 - 0s - loss: 0.5189 - precision_105: 0.8001 - recall_105: 0.7554 - val_loss: 0.5796 - val_precision_105: 0.7772 - val_recall_105: 0.7222\n",
            "Epoch 100/1000\n",
            "1/1 - 0s - loss: 0.5119 - precision_105: 0.8083 - recall_105: 0.7613 - val_loss: 0.5798 - val_precision_105: 0.7828 - val_recall_105: 0.7374\n",
            "Epoch 101/1000\n",
            "1/1 - 0s - loss: 0.5118 - precision_105: 0.8009 - recall_105: 0.7605 - val_loss: 0.5749 - val_precision_105: 0.7871 - val_recall_105: 0.7374\n",
            "Epoch 102/1000\n",
            "1/1 - 0s - loss: 0.5114 - precision_105: 0.8027 - recall_105: 0.7562 - val_loss: 0.5660 - val_precision_105: 0.7802 - val_recall_105: 0.7348\n",
            "Epoch 103/1000\n",
            "1/1 - 0s - loss: 0.5103 - precision_105: 0.8015 - recall_105: 0.7596 - val_loss: 0.5638 - val_precision_105: 0.7661 - val_recall_105: 0.7197\n",
            "Epoch 104/1000\n",
            "1/1 - 0s - loss: 0.5115 - precision_105: 0.7955 - recall_105: 0.7568 - val_loss: 0.5624 - val_precision_105: 0.7763 - val_recall_105: 0.7273\n",
            "Epoch 105/1000\n",
            "1/1 - 0s - loss: 0.5075 - precision_105: 0.7976 - recall_105: 0.7560 - val_loss: 0.5684 - val_precision_105: 0.7751 - val_recall_105: 0.7222\n",
            "Epoch 106/1000\n",
            "1/1 - 0s - loss: 0.5094 - precision_105: 0.8030 - recall_105: 0.7613 - val_loss: 0.5729 - val_precision_105: 0.7751 - val_recall_105: 0.7222\n",
            "Epoch 107/1000\n",
            "1/1 - 0s - loss: 0.5010 - precision_105: 0.8017 - recall_105: 0.7605 - val_loss: 0.5761 - val_precision_105: 0.7742 - val_recall_105: 0.7273\n",
            "Epoch 108/1000\n",
            "1/1 - 0s - loss: 0.4948 - precision_105: 0.8031 - recall_105: 0.7596 - val_loss: 0.5735 - val_precision_105: 0.7775 - val_recall_105: 0.7323\n",
            "Epoch 109/1000\n",
            "1/1 - 0s - loss: 0.5004 - precision_105: 0.8107 - recall_105: 0.7686 - val_loss: 0.5720 - val_precision_105: 0.7865 - val_recall_105: 0.7348\n",
            "Epoch 110/1000\n",
            "1/1 - 0s - loss: 0.5026 - precision_105: 0.7960 - recall_105: 0.7526 - val_loss: 0.5687 - val_precision_105: 0.7769 - val_recall_105: 0.7298\n",
            "Epoch 111/1000\n",
            "1/1 - 0s - loss: 0.4911 - precision_105: 0.8045 - recall_105: 0.7638 - val_loss: 0.5704 - val_precision_105: 0.7739 - val_recall_105: 0.7348\n",
            "Epoch 112/1000\n",
            "1/1 - 0s - loss: 0.5057 - precision_105: 0.8014 - recall_105: 0.7613 - val_loss: 0.5693 - val_precision_105: 0.7802 - val_recall_105: 0.7348\n",
            "Epoch 113/1000\n",
            "1/1 - 0s - loss: 0.4886 - precision_105: 0.8123 - recall_105: 0.7706 - val_loss: 0.5707 - val_precision_105: 0.7865 - val_recall_105: 0.7348\n",
            "Epoch 114/1000\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1/1 - 0s - loss: 0.4827 - precision_105: 0.8079 - recall_105: 0.7737 - val_loss: 0.5700 - val_precision_105: 0.7733 - val_recall_105: 0.7323\n",
            "Epoch 115/1000\n",
            "1/1 - 0s - loss: 0.4920 - precision_105: 0.8076 - recall_105: 0.7720 - val_loss: 0.5702 - val_precision_105: 0.7796 - val_recall_105: 0.7323\n",
            "Epoch 116/1000\n",
            "1/1 - 0s - loss: 0.4901 - precision_105: 0.8109 - recall_105: 0.7709 - val_loss: 0.5702 - val_precision_105: 0.7781 - val_recall_105: 0.7348\n",
            "Epoch 117/1000\n",
            "1/1 - 0s - loss: 0.4849 - precision_105: 0.8183 - recall_105: 0.7779 - val_loss: 0.5701 - val_precision_105: 0.7787 - val_recall_105: 0.7374\n",
            "Epoch 118/1000\n",
            "1/1 - 0s - loss: 0.4802 - precision_105: 0.8122 - recall_105: 0.7751 - val_loss: 0.5698 - val_precision_105: 0.7787 - val_recall_105: 0.7374\n",
            "Epoch 119/1000\n",
            "1/1 - 0s - loss: 0.4854 - precision_105: 0.8101 - recall_105: 0.7714 - val_loss: 0.5696 - val_precision_105: 0.7781 - val_recall_105: 0.7348\n",
            "Epoch 120/1000\n",
            "1/1 - 0s - loss: 0.4847 - precision_105: 0.8081 - recall_105: 0.7697 - val_loss: 0.5693 - val_precision_105: 0.7781 - val_recall_105: 0.7348\n",
            "Epoch 121/1000\n",
            "1/1 - 0s - loss: 0.4894 - precision_105: 0.8129 - recall_105: 0.7737 - val_loss: 0.5690 - val_precision_105: 0.7781 - val_recall_105: 0.7348\n",
            "Epoch 122/1000\n",
            "1/1 - 0s - loss: 0.4844 - precision_105: 0.8222 - recall_105: 0.7832 - val_loss: 0.5686 - val_precision_105: 0.7802 - val_recall_105: 0.7348\n",
            "Epoch 123/1000\n",
            "1/1 - 0s - loss: 0.4808 - precision_105: 0.8096 - recall_105: 0.7700 - val_loss: 0.5683 - val_precision_105: 0.7823 - val_recall_105: 0.7348\n",
            "Epoch 124/1000\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "1/1 - 0s - loss: 0.4897 - precision_105: 0.8091 - recall_105: 0.7678 - val_loss: 0.5679 - val_precision_105: 0.7807 - val_recall_105: 0.7374\n",
            "Epoch 00124: early stopping\n",
            "Score\n",
            "0.7464646464646465\n",
            "\n",
            "\n",
            "Model: \"sequential_109\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_10 (Batc (None, 180, 5)            20        \n",
            "_________________________________________________________________\n",
            "conv1d_69 (Conv1D)           (None, 178, 64)           1024      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_65 (MaxPooling (None, 59, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_417 (Dropout)        (None, 59, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_70 (Conv1D)           (None, 57, 64)            12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_66 (MaxPooling (None, 19, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_40 (Flatten)         (None, 1216)              0         \n",
            "_________________________________________________________________\n",
            "dropout_418 (Dropout)        (None, 1216)              0         \n",
            "_________________________________________________________________\n",
            "dense_381 (Dense)            (None, 256)               311552    \n",
            "_________________________________________________________________\n",
            "dropout_419 (Dropout)        (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_382 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_420 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_383 (Dense)            (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 358,231\n",
            "Trainable params: 358,221\n",
            "Non-trainable params: 10\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}